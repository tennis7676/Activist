{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFWを予想してDB登録\n",
    "- 大株主は浮動の場合もあれば固定の場合もある。自己株式、役員の保有、政策保有株は必ず固定株式\n",
    "- （２）で取得した有価証券報告書に記載されている保有者名を名寄せして浮動株のフラグを付ける\n",
    "- 政策保有株と大株主が上場している場合はは名寄せしてCODEを取得する\n",
    "- FFWの表記は全てDecimal型にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from datetime import datetime, date, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import shutil\n",
    "import mojimoji\n",
    "import math\n",
    "from decimal import Decimal, ROUND_HALF_UP, ROUND_CEILING, ROUND_FLOOR\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "settings_pyodbc = {\"DRIVER\":\"{Oracle in OraClient12Home1}\", \n",
    "                    \"SERVER\":\"E03H.WORLD\", \n",
    "                    \"DBQ\":\"E03H\", \n",
    "                    \"UID\":\"DAZ91001\", \n",
    "                    \"PWD\":\"617030\"}\n",
    "#sqlの呼び出し関数\n",
    "def sql(query):\n",
    "    cnxn = pyodbc.connect(**settings_pyodbc)\n",
    "    return pd.read_sql(query, cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_yuho = r\"S:\\B910\\商品一課\\TOPIXFFW予想\\有価証券報告書抽出後データ\\有価証券報告書\"\n",
    "path_save = r\"S:\\B910\\商品一課\\TOPIXFFW予想\\有価証券報告書集計後データ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_table = 'PTEUC.TOPIX_FFW_ESTIMATE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = date.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#データ区分のフラグ\n",
    "#大株主：１\n",
    "ookabunusi = '1'\n",
    "#自己株式：２\n",
    "jikokabu = '2'\n",
    "#役員：３\n",
    "yakuin = '3'\n",
    "#政策保有株：４\n",
    "seisaku = '4'\n",
    "#発行済み株式数\n",
    "hakkouzumi = '5'\n",
    "#コーポレートアクション\n",
    "ca = '6'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.読込"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#今月から2年前までの月のリストを作成する\n",
    "def make_month_list():\n",
    "    period_datetype_e = date(int(today[0:4]), int(today[4:6]), 1)\n",
    "    month_list = []\n",
    "    for d in range(24):\n",
    "        month = period_datetype_e - relativedelta(months=d)\n",
    "        month_list.append(month.strftime('%Y%m'))\n",
    "    return month_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_list = make_month_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#エクセルから読み込む\n",
    "df_input = pd.DataFrame()\n",
    "for m in month_list:\n",
    "    path_yuho_month = path_yuho + r\"{}.xlsx\".format(m)\n",
    "    if os.path.isfile(path_yuho_month):\n",
    "        df_input_ = pd.read_excel(path_yuho_month, converters={'PERIOD':str, 'F_DATE':str, 'CODE':str, 'NAME':str, 'DATA_KBN':str, 'HOLDER_NAME':str, 'SUB_HOLDER_NAME':str})\n",
    "        df_input = pd.concat([df_input, df_input_])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データが重複して登録されていないかのチェック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RENBAN</th>\n",
       "      <th>PERIOD</th>\n",
       "      <th>F_DATE</th>\n",
       "      <th>CODE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>DATA_KBN</th>\n",
       "      <th>HOLDER_NAME</th>\n",
       "      <th>SUB_HOLDER_NAME</th>\n",
       "      <th>SHARES</th>\n",
       "      <th>SHARES_PRIOR1YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [RENBAN, PERIOD, F_DATE, CODE, NAME, DATA_KBN, HOLDER_NAME, SUB_HOLDER_NAME, SHARES, SHARES_PRIOR1YEAR]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input[df_input.duplicated(['CODE', 'PERIOD', 'RENBAN','DATA_KBN' ])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOLDER_NAMEがNULLのもの"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RENBAN</th>\n",
       "      <th>PERIOD</th>\n",
       "      <th>F_DATE</th>\n",
       "      <th>CODE</th>\n",
       "      <th>NAME</th>\n",
       "      <th>DATA_KBN</th>\n",
       "      <th>HOLDER_NAME</th>\n",
       "      <th>SUB_HOLDER_NAME</th>\n",
       "      <th>SHARES</th>\n",
       "      <th>SHARES_PRIOR1YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1065</th>\n",
       "      <td>1</td>\n",
       "      <td>20231000</td>\n",
       "      <td>20240130</td>\n",
       "      <td>31950</td>\n",
       "      <td>株式会社ジェネレーションパス</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757</th>\n",
       "      <td>0</td>\n",
       "      <td>20230800</td>\n",
       "      <td>20231130</td>\n",
       "      <td>31890</td>\n",
       "      <td>株式会社ＡＮＡＰ</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14657</th>\n",
       "      <td>0</td>\n",
       "      <td>20230300</td>\n",
       "      <td>20230623</td>\n",
       "      <td>82550</td>\n",
       "      <td>アクシアルリテイリング株式会社</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16486</th>\n",
       "      <td>0</td>\n",
       "      <td>20230300</td>\n",
       "      <td>20230623</td>\n",
       "      <td>36120</td>\n",
       "      <td>株式会社ワールド</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32239</th>\n",
       "      <td>0</td>\n",
       "      <td>20230300</td>\n",
       "      <td>20230626</td>\n",
       "      <td>88910</td>\n",
       "      <td>AMGホールディングス株式会社</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81255</th>\n",
       "      <td>0</td>\n",
       "      <td>20230300</td>\n",
       "      <td>20230630</td>\n",
       "      <td>84730</td>\n",
       "      <td>ＳＢＩホールディングス株式会社</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>0</td>\n",
       "      <td>20220800</td>\n",
       "      <td>20221130</td>\n",
       "      <td>31890</td>\n",
       "      <td>株式会社ＡＮＡＰ</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RENBAN    PERIOD    F_DATE   CODE             NAME DATA_KBN  \\\n",
       "1065        1  20231000  20240130  31950   株式会社ジェネレーションパス        4   \n",
       "1757        0  20230800  20231130  31890         株式会社ＡＮＡＰ        4   \n",
       "14657       0  20230300  20230623  82550  アクシアルリテイリング株式会社        4   \n",
       "16486       0  20230300  20230623  36120         株式会社ワールド        4   \n",
       "32239       0  20230300  20230626  88910  AMGホールディングス株式会社        4   \n",
       "81255       0  20230300  20230630  84730  ＳＢＩホールディングス株式会社        4   \n",
       "1719        0  20220800  20221130  31890         株式会社ＡＮＡＰ        4   \n",
       "\n",
       "      HOLDER_NAME SUB_HOLDER_NAME  SHARES  SHARES_PRIOR1YEAR  \n",
       "1065          NaN             NaN     0.0                0.0  \n",
       "1757          NaN             NaN     0.0                0.0  \n",
       "14657         NaN             NaN     0.0                0.0  \n",
       "16486         NaN             NaN     0.0                0.0  \n",
       "32239         NaN             NaN     0.0                0.0  \n",
       "81255         NaN             NaN     0.0                0.0  \n",
       "1719          NaN             NaN     0.0                0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_input[df_input['HOLDER_NAME'].isna()].sort_values('DATA_KBN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定期見直し日の最終営業日\n",
    "def sql_ffw_date(month):\n",
    "    query = f'''\n",
    "SELECT\n",
    "    MAX(D_DATE)\n",
    "FROM\n",
    "    PT2.VWO_FN_CALENDAR\n",
    "WHERE\n",
    "    E_FLG = '1' and\n",
    "    SUBSTR(D_DATE ,0,6) = '{month}'\n",
    "    '''\n",
    "    return sql(query).iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#決算期と定期見直し日の対応表を作成する\n",
    "list_ffw_date = []\n",
    "for m in month_list:\n",
    "    period = str(m) + '00'\n",
    "    if period[4:6] >= '10':\n",
    "        ffw_month = str(int(period[0:4]) +1) + '07'\n",
    "    elif period[4:6] >= '07':\n",
    "        ffw_month = str(int(period[0:4]) +1) + '04'\n",
    "    elif period[4:6] >= '04':\n",
    "        ffw_month = str(int(period[0:4]) +1) + '01'\n",
    "    else:\n",
    "        ffw_month = period[0:4] + '10'\n",
    "    ffw_date = sql_ffw_date(ffw_month)\n",
    "    list_ffw_date.append([period, ffw_date])\n",
    "df_ffw_date = pd.DataFrame(list_ffw_date, columns=['PERIOD', 'FFW_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#最新の決算期\n",
    "max_period = df_input['PERIOD'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#直近のすでに発表されている定期見直し日\n",
    "#直近の公表日＝（1，4，7，10月の第五営業日）を含む最後の営業日\n",
    "def sql_max_ffw_date():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    MAX(D_DATE)\n",
    "FROM\n",
    "    PT2.VWO_FN_CALENDAR\n",
    "WHERE\n",
    "    SUBSTR(D_DATE,0,6) = SUBSTR((\n",
    "            SELECT\n",
    "                MAX(D_DATE)\n",
    "            FROM\n",
    "                (\n",
    "                    SELECT\n",
    "                        D_DATE,\n",
    "                        ROW_NUMBER() OVER(PARTITION BY SUBSTR(D_DATE, 0, 6)\n",
    "                        ORDER BY\n",
    "                            D_DATE) as row_num\n",
    "                    FROM\n",
    "                        PT2.VWO_FN_CALENDAR\n",
    "                    WHERE\n",
    "                        E_FLG = '1' and\n",
    "                        D_DATE<= '{today}' and\n",
    "                        SUBSTR(D_DATE, 5, 2) IN ('01', '04', '07', '10')\n",
    "                )\n",
    "            WHERE\n",
    "                ROW_NUM =5\n",
    "        ), 0, 6 ) and\n",
    "    E_FLG = '1'\n",
    "    '''\n",
    "    return sql(query).iloc[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ffw_date = sql_max_ffw_date()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#予想すべきFFWのリスト\n",
    "list_estimate_ffw_date = df_ffw_date[(df_ffw_date['PERIOD']<=max_period)&(df_ffw_date['FFW_DATE']>max_ffw_date)]['FFW_DATE'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20240731', '20240430']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_estimate_ffw_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メインの関数内で使用する関数\n",
    "- 四半期ごとに参照する有価証券の期間が違う\n",
    "- 1-3月期決算は4月～翌３月までの有価証券報告書。定期見直しは10月\n",
    "- 4-6月期決算は7月～翌6月までの有価証券報告書。定期見直しは1月\n",
    "- 7-9月期決算は10月～翌9月までの有価証券報告書。定期見直しは4月\n",
    "- 10-12月期決算は1月～12月までの有価証券報告書。定期見直しは7月\n",
    "- 予想する定期見直し日はまだ発表されていない日のみ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#今日時点で上場廃止になっている銘柄は抜きたい\n",
    "#吸収合併されていたり、テクニカル上場している可能性があるので二重計上を避けたい\n",
    "def sql_jojo():\n",
    "    query = '''\n",
    "SELECT\n",
    "    CODE\n",
    "FROM\n",
    "    PT2.V_MT_EQ\n",
    "WHERE\n",
    "    JOJO_TSE <> 0 or\n",
    "    JOJO_NSE <> 0 or\n",
    "    JOJO_SSE <> 0 or\n",
    "    JOJO_FSE  <> 0\n",
    "    '''\n",
    "    return sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#マスターと結合するための名寄せ\n",
    "def func_nayose(df, colum):\n",
    "    #新しく列を作る。Nanだとバグルので文字列にする\n",
    "    df[colum + '_NAYOSE'] = df[colum].astype(str)\n",
    "    #すべてこの列に作用させる\n",
    "    colum = colum + '_NAYOSE'\n",
    "    #半角を全角にする\n",
    "    df[colum] = df[colum].apply(mojimoji.han_to_zen)\n",
    "    df[colum] = df[colum].str.replace('㈱', '')\n",
    "    df[colum] = df[colum].str.replace('（株）', '')\n",
    "    df[colum] = df[colum].str.replace('株式会社', '')\n",
    "    df[colum] = df[colum].str.replace('㈲', '有限会社')\n",
    "    df[colum] = df[colum].str.replace('（有）', '有限会社')\n",
    "    #英字を大文字にする\n",
    "    df[colum] = df[colum].str.upper()\n",
    "    #かっこ\n",
    "    df[colum] = df[colum].str.replace('（', '')\n",
    "    df[colum] = df[colum].str.replace('）', '')\n",
    "    df[colum] = df[colum].str.replace('［', '')\n",
    "    df[colum] = df[colum].str.replace('］', '')\n",
    "    #セミコロン\n",
    "    df[colum] = df[colum].str.replace('：', '')\n",
    "    #空白削除\n",
    "    df[colum] = df[colum].replace('\\s', '', regex=True)\n",
    "    \n",
    "    #先頭についている場合はその文字のみ消す\n",
    "    df[colum] = df[colum].replace('^注', '', regex=True)\n",
    "    df[colum] = df[colum].replace('^※', '', regex=True)\n",
    "    df[colum] = df[colum].replace('^＊', '', regex=True)\n",
    "    df[colum] = df[colum].replace('^旧', '', regex=True)\n",
    "    #後ろの場合は全部消す\n",
    "    df[colum] = df[colum].replace('注.*', '', regex=True)\n",
    "    df[colum] = df[colum].replace('※.*', '', regex=True)\n",
    "    df[colum] = df[colum].replace('＊.*', '', regex=True)\n",
    "    df[colum] = df[colum].replace('旧.*', '', regex=True)\n",
    "    #文字を消す\n",
    "    df[colum] = df[colum].str.replace('●', '')\n",
    "    df[colum] = df[colum].str.replace('・', '')\n",
    "    df[colum] = df[colum].str.replace('／', '')\n",
    "    df[colum] = df[colum].str.replace('．', '')\n",
    "    df[colum] = df[colum].str.replace('，', '')\n",
    "    df[colum] = df[colum].str.replace('、', '')\n",
    "    df[colum] = df[colum].str.replace('–', '－')\n",
    "    df[colum] = df[colum].str.replace('-', '－')\n",
    "    df[colum] = df[colum].str.replace('ー', '－')\n",
    "    df[colum] = df[colum].str.replace('―', '－')\n",
    "    df[colum] = df[colum].str.replace('‐', '－')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#子会社特定株式を結合するための結合用\n",
    "def func_nayose_kaisya(df, colum):\n",
    "    #新しく列を作る。Nanだとバグルので文字列にする\n",
    "    df[colum + '_NAYOSE_KAISYA'] = df[colum].astype(str)\n",
    "    #すべてこの列に作用させる\n",
    "    colum = colum + '_NAYOSE_KAISYA'\n",
    "    df[colum] = df[colum].apply(mojimoji.han_to_zen)\n",
    "    #空白削除\n",
    "    df[colum] = df[colum].replace('\\s', '', regex=True)\n",
    "    df[colum] = df[colum].str.replace('㈱', '')\n",
    "    df[colum] = df[colum].str.replace('株式会社', '')\n",
    "    df[colum] = df[colum].str.replace('（株）', '')\n",
    "    df[colum] = df[colum].str.replace('\\(株\\)', '')\n",
    "    df[colum] = df[colum].replace('\\(.*\\)', '', regex=True)\n",
    "    df[colum] = df[colum].replace('（.*）', '', regex=True)\n",
    "    df[colum] = df[colum].replace('信託口.*', '', regex=True)\n",
    "    df[colum] = df[colum].replace('常任代理人.*', '', regex=True)\n",
    "    df[colum] = df[colum].replace('\\d+', '', regex=True)\n",
    "    df[colum] = df[colum].str.replace('（', '')\n",
    "    df[colum] = df[colum].str.replace('）', '')\n",
    "    df[colum] = df[colum].str.replace('［', '')\n",
    "    df[colum] = df[colum].str.replace('］', '')\n",
    "    df[colum] = df[colum].str.replace('・', '')\n",
    "    df[colum] = df[colum].str.replace('–', '－')\n",
    "    df[colum] = df[colum].str.replace('-', '－')\n",
    "    df[colum] = df[colum].str.replace('ー', '－')\n",
    "    df[colum] = df[colum].str.replace('―', '－')\n",
    "    df[colum] = df[colum].str.replace('‐', '－')\n",
    "    df[colum] = df[colum].replace('＜.{0,2}＞', '', regex=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#役員と大株主の重複を削除する用。自己株式（相互保有株式）の重複削除\n",
    "#常任代理人や信託口、括弧の中を消したい\n",
    "#役員の名前の株式会社が存在するため消せない\n",
    "def func_nayose_hito(df, colum):\n",
    "    #新しく列を作る。Nanだとバグルので文字列にする\n",
    "    df[colum + '_NAYOSE_HITO'] = df[colum].astype(str)\n",
    "    #すべてこの列に作用させる\n",
    "    colum = colum + '_NAYOSE_HITO'\n",
    "    df[colum] = df[colum].apply(mojimoji.han_to_zen)\n",
    "    #空白削除\n",
    "    df[colum] = df[colum].replace('\\s', '', regex=True)\n",
    "    #()はすべて削除\n",
    "    df[colum] = df[colum].replace('（.*）', '', regex=True)\n",
    "    #後ろは全部削除\n",
    "    df[colum] = df[colum].replace('信託口.*', '', regex=True)\n",
    "    df[colum] = df[colum].replace('常任代理人.*', '', regex=True)\n",
    "    #数値はすべて削除\n",
    "    df[colum] = df[colum].replace('\\d+', '', regex=True)\n",
    "    df[colum] = df[colum].str.replace('（', '')\n",
    "    df[colum] = df[colum].str.replace('）', '')\n",
    "    df[colum] = df[colum].str.replace('［', '')\n",
    "    df[colum] = df[colum].str.replace('］', '')\n",
    "    df[colum] = df[colum].str.replace('・', '')\n",
    "    df[colum] = df[colum].str.replace('–', '－')\n",
    "    df[colum] = df[colum].str.replace('-', '－')\n",
    "    df[colum] = df[colum].str.replace('ー', '－')\n",
    "    df[colum] = df[colum].str.replace('―', '－')\n",
    "    df[colum] = df[colum].str.replace('‐', '－')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#決算期以降にコーポレートアクションで固定株が変化した分を加える。第三者割当は固定株増加。自己株式消却は固定株減少\n",
    "# 全て定期見直し日の前月にコーポレートアクションが行われたと仮定する（第三社割り当ては実際は7営業日前だが複雑になるので前月にする）\n",
    "# DATA_KBN = 6としてmainに加える\n",
    "#06：第三者割当\n",
    "#08：CB転換\n",
    "#14：会社合併\n",
    "#18：優先株の転換\n",
    "#90：その他\n",
    "#J1：自己株消却\n",
    "def sql_fixed_shares_ca():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    A.CODE,\n",
    "    A.CHG_DATE as CHG_DATE_CA,\n",
    "    A.EVENT_CODE,\n",
    "    TO_CHAR(TRUNC(TO_NUMBER(TO_CHAR(ADD_MONTHS(TO_DATE(A.CHG_DATE, 'YYYYMMDD'), -1), 'YYYYMMDD'))/100)*100) as PERIOD_CA,\n",
    "    ROUND(A.ADD_JOJOKABUSU/B.FFW_NEW, 0) as SHARES,\n",
    "    '6' as DATA_KBN,\n",
    "    '0' as FFW_FLG\n",
    "    \n",
    "FROM\n",
    "    PT2.V_MD_CHG_BASE_TOPIX A,\n",
    "    PT2.V_MD_CHG_BASE_TOPIX B\n",
    "WHERE\n",
    "    A.CODE = B.CODE and\n",
    "    A.PUBLIC_DATE=B.PUBLIC_DATE and\n",
    "    A.CHG_DATE = B.CHG_DATE and\n",
    "    A.EVENT_CODE IN ('06', '08', '14', '18', '90', 'J1') and\n",
    "    B.EVENT_CODE = 'FR' and\n",
    "    A.DEL_FLG = '0' and\n",
    "    B.DEL_FLG = '0' and\n",
    "    A.ADD_JOJOKABUSU is NOT NULL and\n",
    "    A.CHG_DATE >= '{min(month_list)}'\n",
    "    '''\n",
    "    return sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 株式分割や併合\n",
    "# 決算期末に分割併合があった場合は分割併合前の株数で大株主、自己株式、役員の状況は表示されている。\n",
    "# 一方で政策保有株は会社によって分割併合前と後でどのように表示するか定まっていない\n",
    "def sql_bunkatu():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    CHG_DATE as CHG_DATE_BUNKATU,\n",
    "    SUBSTR(CHG_DATE,0,6) || '00' as PERIOD_BUNKATU,\n",
    "    CODE,\n",
    "    ALOC_RT_R / ALOC_RT_L as BUNKATU\n",
    "FROM\n",
    "    PT2.V_MD_CHG_BASE_TOPIX\n",
    "WHERE\n",
    "    EVENT_CODE IN( '15', 'B1') and\n",
    "    CHG_DATE >= '{min(month_list)}' \n",
    "ORDER BY\n",
    "    CHG_DATE\n",
    "    '''\n",
    "    return sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#株式分割併合の割合するための関数\n",
    "def func_bunkatu(x, df_bunkatu):\n",
    "    #分割併合前の株数を表示している場合\n",
    "    #CAの場合\n",
    "    if x['DATA_KBN'] == ca:\n",
    "        #有報よりも後でかつCAが分割日よりも前\n",
    "        df_bunkatu_ca = df_bunkatu[(df_bunkatu['CODE'] == x['CODE']) & (df_bunkatu['CHG_DATE_BUNKATU'] > x['CHG_DATE_CA']) & (df_bunkatu['PERIOD_BUNKATU'] < x['FFW_DATE'])]\n",
    "        if len(df_bunkatu_ca)>0:\n",
    "            return df_bunkatu_ca['BUNKATU'].prod()\n",
    "        else:\n",
    "            return 1\n",
    "    #大株主、自己株式、役員、発行済み株式、政策保有株\n",
    "    else:\n",
    "        df_bunkatu_ex = df_bunkatu[(df_bunkatu['CODE'] == x['CODE']) & (df_bunkatu['PERIOD_BUNKATU']>=x['PERIOD']) & (df_bunkatu['PERIOD_BUNKATU'] < x['FFW_DATE']) ]\n",
    "        if len(df_bunkatu_ex)>0:\n",
    "            return df_bunkatu_ex['BUNKATU'].prod()\n",
    "        else:\n",
    "            return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 政策保有株に関して分割併合を考慮する場合は　①前年度の株数 * 分割併合　＝　今年の株数（±１％）ならばすでに分割されているとみなす\n",
    "def func_bunkatu_shares(x):\n",
    "    if x['DATA_KBN'] == 4:\n",
    "        #すでに株式分割後なので分割併合をかけない\n",
    "        if (abs(x['SHARES']-x['SHARES_PRIOR1YEAR']*x['BUNKATU']) <= (x['SHARES']*0.01)):\n",
    "            return x['SHARES']\n",
    "        else:\n",
    "            return x['SHARES']*x['BUNKATU']\n",
    "    else:\n",
    "        return x['SHARES']*x['BUNKATU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#固定株を求める\n",
    "def func_ffw_shares(x):\n",
    "    #固定株\n",
    "    if x['FFW_FLG'] == '0':\n",
    "        return x['SHARES_BUNKATU']\n",
    "    #浮動株\n",
    "    elif x['FFW_FLG'] == '2':\n",
    "        return 0\n",
    "    else:\n",
    "        return x['SHARES_BUNKATU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定期見直しの対象となる銘柄を取ってくる\n",
    "#新規上場銘柄は有報が出ていれば定期見直しされる\n",
    "def sql_topix():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    A.CODE,\n",
    "    B.NAME\n",
    "FROM\n",
    "    PT2.V_MD_EQ_BASE_TOPIX_S A\n",
    "LEFT OUTER JOIN\n",
    "    PT2.V_MT_EQ B ON\n",
    "    A.CODE = B.CODE\n",
    "WHERE\n",
    "    A.D_DATE = '{today}' AND\n",
    "    A.SIZE2 <='7'\n",
    "    '''\n",
    "    return sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 調整係数を適用する\n",
    "# 基準は2月末で4月５営業日に公表される。4月末に適応される\n",
    "def sql_tyousei():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    CODE,\n",
    "    TYOUSEI_KEISU_OLD,\n",
    "    TYOUSEI_KEISU_NEW\n",
    "FROM\n",
    "    PTEUC.TOPIX_FFW_TYOUSEI_KEISU_ESTIMATE\n",
    "WHERE\n",
    "    D_DATE = '{today}'     \n",
    "    '''\n",
    "    return sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 移行係数を適用する\n",
    "# 段階的ウェイト低減銘柄に適応される。四半期ごとに0.1ずつ減らされる。再評価時に100億円以上かつ年間売買代金回転率0.2以下となった場合0.6のまま維持。100億円以上かつ年間売買代金回転率0.2以上となった場合は0.1ずつ回復する。\n",
    "# 現時点で存在する全ての情報を入れるため除外は0復活する銘柄は１にする\n",
    "def sql_ikou_keisu(today, x_date):\n",
    "    query = f'''\n",
    "SELECT\n",
    "    A.CODE,\n",
    "    NVL(A.IKOU_KEISU, 1) as IKOU_KEISU_OLD,\n",
    "    NVL(B.IKOU_KEISU,1) as IKOU_KEISU_NEW\n",
    "FROM\n",
    "    (\n",
    "        SELECT\n",
    "            *\n",
    "        FROM\n",
    "            PTEUC.TOPIX_FFW_IKOU_KEISU\n",
    "        WHERE\n",
    "            FFW_DATE = (\n",
    "                SELECT\n",
    "                    MAX(FFW_DATE)\n",
    "                FROM\n",
    "                    PTEUC.TOPIX_FFW_IKOU_KEISU\n",
    "                WHERE\n",
    "                    FFW_DATE<='{today}'\n",
    "            )\n",
    "    )A\n",
    "    FULL OUTER JOIN (\n",
    "            SELECT\n",
    "                *\n",
    "            FROM\n",
    "                PTEUC.TOPIX_FFW_IKOU_KEISU\n",
    "            WHERE\n",
    "                FFW_DATE = '{x_date}'\n",
    "        ) B ON\n",
    "        A.CODE = B.CODE\n",
    "\n",
    "    ORDER BY A.FFW_DATE,\n",
    "    A.CODE\n",
    "    '''\n",
    "    return sql(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 現在の情報を追加\n",
    "## FFW_OLD, TOB_FLG, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#当日時点のFFW\n",
    "def sql_ffw_old():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    D_DATE,\n",
    "    CODE,\n",
    "    SIZE2,\n",
    "    FFW as FFW_OLD\n",
    "FROM\n",
    "    PT2.V_MD_EQ_BASE_TOPIX_S\n",
    "WHERE\n",
    "    D_DATE = '{today}' and\n",
    "    SIZE2 <= '7'\n",
    "    '''\n",
    "    return sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#前回のFFW変更以降にTOBされている銘柄\n",
    "#予想している日付の一番小さいもの以降で\n",
    "def sql_tob(event_period):\n",
    "    query = f'''\n",
    "SELECT\n",
    "  CODE,\n",
    "  PTRN_FLG as TOB_FLG\n",
    "FROM\n",
    "    PT2.V_MD_CA_TOB\n",
    "WHERE TOB_END_DATE >= '{event_period}' \n",
    "    '''\n",
    "    return sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_event(event_period):\n",
    "    query = f'''\n",
    "SELECT\n",
    "    CODE,\n",
    "    LISTAGG(EVENT_CODE, ',') as EVENT_CODE\n",
    "FROM\n",
    "    (\n",
    "        SELECT\n",
    "            UNIQUE CODE,\n",
    "            EVENT_CODE\n",
    "        FROM\n",
    "            PT2.V_MD_CHG_BASE_TOPIX\n",
    "        WHERE\n",
    "            CHG_DATE >= '{event_period}' \n",
    "    )\n",
    "GROUP BY\n",
    "    CODE\n",
    "ORDER BY\n",
    "    CODE\n",
    "    '''\n",
    "    return sql(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DB挿入\n",
    "def is_exist_today(insert_table, x_date):\n",
    "    query = f'''\n",
    "SELECT COUNT(*)    \n",
    "FROM {insert_table}\n",
    "WHERE D_DATE = '{today}' and \n",
    "      FFW_DATE = '{x_date}'\n",
    "    '''\n",
    "    return sql(query).iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Insert_DB(insert_table, df, x_date):\n",
    "        keys = ','.join(list(df.columns))\n",
    "        with pyodbc.connect(DRIVER=\"{Oracle in OraClient12Home1}\", \n",
    "                              SERVER=\"E03H.WORLD\", \n",
    "                              DBQ=\"E03H\", \n",
    "                              UID=\"DAZ91001\", \n",
    "                              PWD=\"617030\") as cnxn:\n",
    "            with cnxn.cursor() as cursor:\n",
    "                #当日が既に登録されていたら削除\n",
    "                if is_exist_today(insert_table, x_date):\n",
    "                    delete_sql = f'''\n",
    "                    DELETE\n",
    "                    FROM {insert_table}\n",
    "                    WHERE D_DATE = {today} and \n",
    "                          FFW_DATE = {x_date}\n",
    "                    '''\n",
    "                    cursor.execute(delete_sql)\n",
    "                #ここからDB登録\n",
    "                for row in df.values:\n",
    "                    values = ''\n",
    "                    for cell in row:\n",
    "                        if type(cell) is str:\n",
    "                            values += f\"'{cell}',\"\n",
    "                        elif pd.isna(cell) or (cell is None):\n",
    "                            values += 'NULL,'\n",
    "                        else:\n",
    "                            values += f\"{cell},\"\n",
    "                    #最後のカンマを消す\n",
    "                    values = values[0:-1]\n",
    "                    \n",
    "                    insert_sql = f'insert into {insert_table} ({keys}) VALUES ({values})'\n",
    "                    # sql実行\n",
    "                    cursor.execute(insert_sql)\n",
    "                    cursor.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メイン関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_estimate(x_date):\n",
    "    #予想する決算期\n",
    "    list_estimate_period = df_ffw_date[df_ffw_date['FFW_DATE'] == x_date]['PERIOD'].tolist()\n",
    "    #使用する有報の範囲を絞る\n",
    "    df_yuho = df_input[df_input['PERIOD']<=max(list_estimate_period)].copy()\n",
    "    #ユニークなものを抽出\n",
    "    df_kessan = df_yuho.groupby(['CODE', 'PERIOD', 'F_DATE']).sum().reset_index()[['CODE', 'PERIOD', 'F_DATE']]\n",
    "    #並べ替えて最新の決算期のみを残す\n",
    "    df_kessan1 = df_kessan.sort_values(['CODE', 'PERIOD']).drop_duplicates('CODE', keep='last')\n",
    "    #今日時点で上場廃止になっている銘柄は抜きたい。吸収合併されていたり、テクニカル上場している可能性があるので二重計上を避けたい\n",
    "    #現在上場している銘柄リスト\n",
    "    df_jojo = sql_jojo()\n",
    "    #現在上場している銘柄のみにする\n",
    "    df_kessan2 = df_kessan1[df_kessan1['CODE'].isin(df_jojo['CODE'].values)]\n",
    "    #決算期と定期見直し日の対応表をくっつける\n",
    "    df_kessan3 = pd.merge(df_kessan2, df_ffw_date, on='PERIOD', how='left')\n",
    "    #最新の決算のみにする\n",
    "    df_yuho_unique = pd.merge(df_kessan3, df_yuho, on=['CODE', 'PERIOD', 'F_DATE'], how='left')\n",
    "    #株数がNULLの行を0埋めする\n",
    "    df_yuho_unique['SHARES'] = df_yuho_unique['SHARES'].fillna(0)\n",
    "    #役員と政策保有株は保有株が０でも行が存在するので削除する\n",
    "    df_yuho_unique = df_yuho_unique[~((df_yuho_unique['SHARES'] ==0) & (df_yuho_unique['DATA_KBN'].isin(['3', '4'])))].copy()\n",
    "    #マスターと結合するための列を追加\n",
    "    df_yuho_nayose = func_nayose(df_yuho_unique,'HOLDER_NAME')\n",
    "    df_yuho_nayose1 = func_nayose_kaisya(df_yuho_unique,'HOLDER_NAME')\n",
    "    df_yuho_nayose2 = func_nayose_hito(df_yuho_unique,'HOLDER_NAME')\n",
    "    #名寄せ用のエクセルパスの取得\n",
    "    path_master = glob.glob(r\"S:\\B910\\商品一課\\TOPIXFFW予想\\マスター\\topix_ffw_master*.xlsx\")[0]\n",
    "    #名寄せマスターの読込。0:固定、１：浮動、２：不明\n",
    "    df_ffw_master = pd.read_excel(path_master, converters={'MASTER_CODE':str, 'FFW_FLG':str})[['MASTER_NAME', 'MASTER_CODE', 'FFW_FLG']].copy()\n",
    "    #念のため重複を削除する\n",
    "    df_ffw_master = df_ffw_master.drop_duplicates('MASTER_NAME')\n",
    "    #浮動固定判定のためのフラグを有報に結合\n",
    "    df_yuho_master = pd.merge(df_yuho_nayose2, df_ffw_master, left_on='HOLDER_NAME_NAYOSE', right_on='MASTER_NAME', how='left')\n",
    "    #大株主、自己株式、役員、政策保有株、発行済み株でそれぞれ分ける\n",
    "    df_ookabunusi = df_yuho_master[df_yuho_master['DATA_KBN']==ookabunusi].copy()\n",
    "    df_jikokabu = df_yuho_master[df_yuho_master['DATA_KBN']==jikokabu].copy()\n",
    "    df_yakuin = df_yuho_master[df_yuho_master['DATA_KBN']==yakuin].copy()\n",
    "    df_seisaku = df_yuho_master[df_yuho_master['DATA_KBN']==seisaku].copy()\n",
    "    df_hakkouzumi = df_yuho_master[df_yuho_master['DATA_KBN']==hakkouzumi].copy()\n",
    "    #大株主との重複を削除する\n",
    "    #マージした時のフラグ用\n",
    "    df_ookabunusi['OOKABUNUSI_FLG'] = '1'\n",
    "    #1自己株式の重複削除。一部である相互保有株式は大株主に出てくる可能性があるので削除する。株式会社を削除していない人用の名寄せで重複を削除する。小野建株式会社と小野建で重複削除するのを防ぐため。\n",
    "    df_jikokabu1 = pd.merge(df_jikokabu, df_ookabunusi[['CODE', 'HOLDER_NAME_NAYOSE_HITO', 'OOKABUNUSI_FLG']], on=['CODE', 'HOLDER_NAME_NAYOSE_HITO'], how='left')\n",
    "    df_jikokabu2 = df_jikokabu1[df_jikokabu1['OOKABUNUSI_FLG'].isnull()]\n",
    "    #2役員の重複削除\n",
    "    df_yakuin1 = pd.merge(df_yakuin, df_ookabunusi[['CODE', 'HOLDER_NAME_NAYOSE_HITO', 'OOKABUNUSI_FLG']], on=['CODE', 'HOLDER_NAME_NAYOSE_HITO'], how='left')\n",
    "    df_yakuin2 = df_yakuin1[df_yakuin1['OOKABUNUSI_FLG'].isnull()]\n",
    "    #3政策保有株の重複を削除\n",
    "    # 親会社が保有している場合は１銘柄コード、２名称で削除する（テクニカル上場した場合大株主の銘柄コードはマスターから（5830）政策保有株の銘柄コードは有報の提出会社から（83850）取っているため重複削除できない）\n",
    "    # 子会社が保有している場合は大株主の名称が政策保有株の親会社の名前もしくは子会社の名前で削除する\n",
    "    #大株主でも銘柄コードが付いていないものは重複することがないので削除する\n",
    "    df_ookabunusi1 = df_ookabunusi[~((df_ookabunusi['MASTER_CODE'].isnull()) | (df_ookabunusi['MASTER_CODE']=='0'))]\n",
    "    #政策保有株は保有する側とされる側が逆になっているのでひっくり返す\n",
    "    df_seisaku1 = df_seisaku.rename({'HOLDER_NAME':'NAME', 'NAME':'HOLDER_NAME', 'CODE':'MASTER_CODE', 'MASTER_CODE':'CODE'}, axis=1)\n",
    "    #この状態でのHOLDER_NAME_NAYOSEは提出会社の名寄せになっているため、ひっくり返した後にもう一度名寄せを行って上書きする\n",
    "    df_seisaku2 = func_nayose_kaisya(df_seisaku1,'HOLDER_NAME')\n",
    "    #ここでCODEが0になっている銘柄は非上場なので無視する\n",
    "    df_seisaku3 = df_seisaku2[df_seisaku2['CODE']!='0'].copy()\n",
    "    #子会社特定株式と普通の株式で分ける\n",
    "    df_seisaku_oya = df_seisaku3[pd.isnull(df_seisaku3['SUB_HOLDER_NAME']) | (df_seisaku3['SUB_HOLDER_NAME']=='nan')].copy()\n",
    "    df_seisaku_ko = df_seisaku3[~(pd.isnull(df_seisaku3['SUB_HOLDER_NAME']) | (df_seisaku3['SUB_HOLDER_NAME']=='nan'))].copy()\n",
    "    ##3-1親会社の削除\n",
    "    df_seisaku_oya1 = pd.merge(df_seisaku_oya, df_ookabunusi1[['CODE', 'MASTER_CODE', 'OOKABUNUSI_FLG']], on=['CODE', 'MASTER_CODE'], how='left')\n",
    "    df_seisaku_oya2 = pd.merge(df_seisaku_oya1, df_ookabunusi1[['CODE', 'HOLDER_NAME_NAYOSE_KAISYA', 'OOKABUNUSI_FLG']], on=['CODE', 'HOLDER_NAME_NAYOSE_KAISYA'], how='left')\n",
    "    df_seisaku_oya3 = df_seisaku_oya2[~((df_seisaku_oya2['OOKABUNUSI_FLG_x']=='1') | (df_seisaku_oya2['OOKABUNUSI_FLG_y']=='1'))].copy()\n",
    "    #3-2子会社の削除    \n",
    "    #子会社名でも結合したいので子会社名も名寄せする\n",
    "    df_seisaku_ko1 = func_nayose_kaisya(df_seisaku_ko,'SUB_HOLDER_NAME')\n",
    "    #初めは親会社の名前で\n",
    "    df_seisaku_ko2 = pd.merge(df_seisaku_ko1, df_ookabunusi1[['CODE', 'HOLDER_NAME_NAYOSE_KAISYA', 'OOKABUNUSI_FLG']], on=['CODE', 'HOLDER_NAME_NAYOSE_KAISYA'], how='left')\n",
    "    #次に子会社の名前で\n",
    "    df_seisaku_ko3 = pd.merge(df_seisaku_ko2, df_ookabunusi1[['CODE', 'HOLDER_NAME_NAYOSE_KAISYA', 'OOKABUNUSI_FLG']], left_on=['CODE', 'SUB_HOLDER_NAME_NAYOSE_KAISYA'], right_on=['CODE', 'HOLDER_NAME_NAYOSE_KAISYA'], how='left')\n",
    "    #大株主10位の名前が政策保有株の親会社の名前でもなく、子会社の名前でもない場合は重複していないと考えて削除しない。\n",
    "    df_seisaku_ko4 = df_seisaku_ko3[~((df_seisaku_ko3['OOKABUNUSI_FLG_x']=='1') | (df_seisaku_ko3['OOKABUNUSI_FLG_y']=='1'))].copy()\n",
    "    #3-3政策保有株内での削除。三菱ケミカルGと日本産酸素のように子会社が上場している場合は2回有報の中に出現するので削除する。子の方を削除。\n",
    "    #政策保有株内の重複を消すため用の名寄せ\n",
    "    df_seisaku_oya3['SEISAKU_OYA_FLG'] = '1'\n",
    "    df_seisaku_ko5 = pd.merge(df_seisaku_ko4, df_seisaku_oya3[['CODE', 'HOLDER_NAME_NAYOSE_KAISYA', 'SEISAKU_OYA_FLG']], left_on=['CODE', 'SUB_HOLDER_NAME_NAYOSE_KAISYA'], right_on=['CODE', 'HOLDER_NAME_NAYOSE_KAISYA'], how='left')\n",
    "    df_seisaku_ko6 = df_seisaku_ko5[df_seisaku_ko5['SEISAKU_OYA_FLG'].isnull()]\n",
    "    df_main = pd.concat([df_ookabunusi, df_jikokabu2, df_yakuin2, df_seisaku_oya3, df_seisaku_ko6])    \n",
    "    #コーポレートアクションの株数を加える\n",
    "    df_fixed_shaes_ca = sql_fixed_shares_ca()\n",
    "    df_fixed_shaes_ca1 = pd.merge(df_fixed_shaes_ca, df_kessan3, on='CODE', how='left')\n",
    "    #考慮するコーポレートアクションは「決算期＜コーポレートアクションの実質月＜定期見直し月」\n",
    "    df_fixed_shaes_ca2 = df_fixed_shaes_ca1[(df_fixed_shaes_ca1['PERIOD_CA'] > df_fixed_shaes_ca1['PERIOD']) & (df_fixed_shaes_ca1['PERIOD_CA'] < df_fixed_shaes_ca1['FFW_DATE'])]\n",
    "    df_main1 = pd.concat([df_main, df_hakkouzumi, df_fixed_shaes_ca2])\n",
    "    #株式分割併合\n",
    "    df_bunkatu = sql_bunkatu()\n",
    "    #株式分割併合の時期と有報の決算期の時期を加味して分割割合の列を加える\n",
    "    df_main1['BUNKATU'] = df_main1.apply(lambda x:func_bunkatu(x, df_bunkatu), axis=1)\n",
    "    #分割後の株数を加える。政策保有株は前年度との増加で分割併合の前か後か確認している\n",
    "    df_main1['SHARES_BUNKATU'] = df_main1.apply(lambda x:func_bunkatu_shares(x), axis=1)\n",
    "    #自己株式、役員、政策保有は必ず固定株なので0を入れる\n",
    "    df_main1.loc[df_main1['DATA_KBN'].isin([2,3,4]), 'FFW_FLG'] = 0\n",
    "    #固定株とみなす株数\n",
    "    df_main1['FIXED_SHARES'] = df_main1.apply(lambda x: func_ffw_shares(x), axis=1)\n",
    "    # 政府保有分の修正\n",
    "    #JT2914\n",
    "    df_main1.loc[(df_main1['CODE']=='29140') & (df_main1['DATA_KBN']=='5'), 'SHARES_BUNKATU'] = (df_main1.loc[(df_main1['CODE']=='29140') & (df_main1['DATA_KBN']=='5')]['SHARES_BUNKATU'].iloc[0] - df_main1.loc[(df_main1['CODE']=='29140') & (df_main1['HOLDER_NAME_NAYOSE']=='財務大臣')]['SHARES_BUNKATU'].iloc[0] )\n",
    "    #日本郵政6178\n",
    "    df_main1.loc[(df_main1['CODE']=='61780') & (df_main1['DATA_KBN']=='5'), 'SHARES_BUNKATU'] = (df_main1.loc[(df_main1['CODE']=='61780') & (df_main1['DATA_KBN']=='5')]['SHARES_BUNKATU'].iloc[0] - df_main1.loc[(df_main1['CODE']=='61780') & (df_main1['HOLDER_NAME_NAYOSE']=='財務大臣')]['SHARES_BUNKATU'].iloc[0] )\n",
    "    #NTT9432\n",
    "    df_main1.loc[(df_main1['CODE']=='94320') & (df_main1['DATA_KBN']=='5'), 'SHARES_BUNKATU'] = (df_main1.loc[(df_main1['CODE']=='94320') & (df_main1['DATA_KBN']=='5')]['SHARES_BUNKATU'].iloc[0] - df_main1.loc[(df_main1['CODE']=='94320') & (df_main1['HOLDER_NAME_NAYOSE']=='財務大臣')]['SHARES_BUNKATU'].iloc[0] )\n",
    "    #列を整える\n",
    "    df_main2 = df_main1[['HOLDER_NAME', 'SHARES', 'DATA_KBN', 'SHARES_PRIOR1YEAR', 'F_DATE', 'CODE', 'NAME', 'PERIOD', 'SUB_HOLDER_NAME', 'HOLDER_NAME_NAYOSE', 'MASTER_CODE', 'FFW_FLG', 'CHG_DATE_CA', 'BUNKATU', 'SHARES_BUNKATU', 'FIXED_SHARES']].copy()\n",
    "    #FFW_DATEのフォルダが存在していなければ作る\n",
    "    if not(os.path.isdir(path_save + r\"\\{}\".format(x_date))):\n",
    "        os.mkdir(path_save + r\"\\{0}\".format(x_date))\n",
    "    df_main2.astype({'DATA_KBN':int, 'F_DATE':float, 'PERIOD':float,  'MASTER_CODE':float, 'FFW_FLG':float}).to_excel(r\"S:\\B910\\商品一課\\TOPIXFFW予想\\有価証券報告書集計後データ\\{0}\\main_{0}_{1}.xlsx\".format(x_date, today))\n",
    "    # 合計して銘柄ごとの固定株を求める\n",
    "    #固定株の合計\n",
    "    df_main_sum = df_main1[~df_main1['DATA_KBN'].isin([hakkouzumi, ca])].groupby(['CODE'])[['FIXED_SHARES']].sum().reset_index()\n",
    "    #コーポレートアクションの合計\n",
    "    df_main_sum_ca = df_main1[df_main1['DATA_KBN']==ca].groupby(['CODE'])[['FIXED_SHARES']].sum().reset_index().rename({'FIXED_SHARES':'FIXED_SHARES_CA'}, axis=1)\n",
    "    #発行済み株式\n",
    "    df_hakkouzumi_bunkatu = df_main1[df_main1['DATA_KBN']==hakkouzumi][['CODE', 'SHARES_BUNKATU']].rename({'SHARES_BUNKATU':'YUHOKABUSU'}, axis=1)\n",
    "    #今日topixに採用されている銘柄\n",
    "    df_topix = sql_topix()\n",
    "    #topix_採用銘柄かつ当該定期見直しの対象の銘柄に絞り込む\n",
    "    df_kessan_topix = pd.merge(df_topix, df_kessan3, on='CODE', how='left')\n",
    "    #決算期を加える\n",
    "    df_ffw_sum1 = pd.merge(df_kessan_topix, df_main_sum, on=['CODE'], how='left')\n",
    "    #コーポレートアクションの列を加える\n",
    "    df_ffw_sum2 = pd.merge(df_ffw_sum1, df_main_sum_ca, on=['CODE'], how='left')\n",
    "    #発行済み株数の列を加える\n",
    "    df_ffw_sum3 = pd.merge(df_ffw_sum2, df_hakkouzumi_bunkatu, on='CODE', how='left')\n",
    "    #CAの株数のNULLを埋める\n",
    "    df_ffw_sum3['FIXED_SHARES_CA'] = df_ffw_sum3['FIXED_SHARES_CA'].fillna(0)\n",
    "    ## folatだと正確な10進法ではない。切上でずれるのでdecimal型にする\n",
    "    df_ffw_sum3['FIXED_SHARES'] = df_ffw_sum3['FIXED_SHARES'].apply(lambda x:Decimal(str(x)))\n",
    "    df_ffw_sum3['FIXED_SHARES_CA'] = df_ffw_sum3['FIXED_SHARES_CA'].apply(lambda x:Decimal(str(x)))\n",
    "    df_ffw_sum3['YUHOKABUSU'] = df_ffw_sum3['YUHOKABUSU'].apply(lambda x:Decimal(str(x)))\n",
    "    #固定株比率は小数点3桁目を四捨五入する\n",
    "    df_ffw_sum3['FIXED_SHARES_RATIO'] = ((df_ffw_sum3['FIXED_SHARES_CA']+df_ffw_sum3['FIXED_SHARES'])/(df_ffw_sum3['YUHOKABUSU']+df_ffw_sum3['FIXED_SHARES_CA'])).apply(lambda x:x.quantize(Decimal('0.01'), rounding=ROUND_HALF_UP))\n",
    "    #浮動株比率は(1-固定株比率)を0.05単位で切上\n",
    "    df_ffw_sum3['FFW_ESTIMATED'] = ((1-df_ffw_sum3['FIXED_SHARES_RATIO'])*Decimal('100')/Decimal('5')).apply(lambda x:x.quantize(Decimal('0'), rounding=ROUND_CEILING))*Decimal('5')/Decimal('100')\n",
    "    #調整係数\n",
    "    df_tyousei = sql_tyousei()\n",
    "    df_tyousei['TYOUSEI_KEISU_OLD'] = df_tyousei['TYOUSEI_KEISU_OLD'].apply(lambda x:Decimal(str(x)))\n",
    "    df_tyousei['TYOUSEI_KEISU_NEW'] = df_tyousei['TYOUSEI_KEISU_NEW'].apply(lambda x:Decimal(str(x)))\n",
    "    df_ffw_sum4 = pd.merge(df_ffw_sum3, df_tyousei, on='CODE', how='left')\n",
    "    df_ffw_sum4['TYOUSEI_KEISU_OLD'] = df_ffw_sum4['TYOUSEI_KEISU_OLD'].fillna(Decimal('1'))\n",
    "    df_ffw_sum4['TYOUSEI_KEISU_NEW'] = df_ffw_sum4['TYOUSEI_KEISU_NEW'].fillna(Decimal('1'))\n",
    "    #移行係数\n",
    "    df_ikou = sql_ikou_keisu(today, x_date)\n",
    "    df_ikou['IKOU_KEISU_OLD'] = df_ikou['IKOU_KEISU_OLD'].apply(lambda x:Decimal(str(x)))\n",
    "    df_ikou['IKOU_KEISU_NEW'] = df_ikou['IKOU_KEISU_NEW'].apply(lambda x:Decimal(str(x)))\n",
    "    df_ffw_sum5 = pd.merge(df_ffw_sum4, df_ikou, on='CODE', how='left')\n",
    "    df_ffw_sum5['IKOU_KEISU_OLD'] = df_ffw_sum5['IKOU_KEISU_OLD'].fillna(Decimal('1'))\n",
    "    df_ffw_sum5['IKOU_KEISU_NEW'] = df_ffw_sum5['IKOU_KEISU_NEW'].fillna(Decimal('1'))\n",
    "    #調整係数と移行係数を適用する\n",
    "    df_ffw_sum5['FFW_NEW'] = df_ffw_sum5['FFW_ESTIMATED'] * df_ffw_sum5['TYOUSEI_KEISU_NEW'] * df_ffw_sum5['IKOU_KEISU_NEW']\n",
    "    df_out = df_ffw_sum5[df_ffw_sum5['FFW_DATE']==x_date]\n",
    "    #ここからは現在の情報を加える\n",
    "    df_ffw_old = sql_ffw_old()\n",
    "    df_out1 = pd.merge(df_out, df_ffw_old, on='CODE', how='left')\n",
    "    #tobとイベントはざっくりチェックのためのみだからこれでいいや\n",
    "    event_period = int(df_out['PERIOD'].min()) - 1\n",
    "    df_tob = sql_tob(event_period)\n",
    "    df_out2 = pd.merge(df_out1, df_tob, on='CODE', how='left')\n",
    "    df_out2['TOB_FLG'] = df_out2['TOB_FLG'].fillna(0)\n",
    "    df_event = sql_event(event_period)\n",
    "    df_out3 = pd.merge(df_out2, df_event, on='CODE', how='left')\n",
    "    df_insert_table = df_out3.astype({'PERIOD':float, 'F_DATE':float, 'FFW_DATE':int, 'FIXED_SHARES':float, 'FIXED_SHARES_CA':float, 'YUHOKABUSU':float, 'FIXED_SHARES_RATIO':float, 'FFW_ESTIMATED':float, 'TYOUSEI_KEISU_OLD':float, 'TYOUSEI_KEISU_NEW':float, 'IKOU_KEISU_OLD':float, 'IKOU_KEISU_NEW':float, 'FFW_NEW':float, 'FFW_OLD':float, 'D_DATE':int, 'SIZE2':int})\n",
    "    df_insert_table['D_DATE'] = today\n",
    "    df_insert_table.to_excel(path_save + r\"\\{0}\\main_sum_{0}_{1}.xlsx\".format(x_date, today))\n",
    "    Insert_DB(insert_table, df_insert_table, x_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x_date in list_estimate_ffw_date:\n",
    "    func_estimate(x_date)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
