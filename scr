from selenium import webdriver
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import Select
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC

import requests
from bs4 import BeautifulSoup
from datetime import datetime
import time
import glob
import cx_Oracle
import pandas as pd

def FetchDataFromDB(_sql):
    try:
        with cx_Oracle.connect('DAZ91001', '617030', 'E03H') as conn:
            df = pd.read_sql(_sql, conn)
            df.columns = df.columns.str.lower()
            return df

    except Exception as ex:
        print("DBからデータ取得時にエラー")
        print(ex)
        return None

SaveDir = 'R:/B984/Users/Kikuchi/PM/Analysis/buyback/PDF/'

driver = webdriver.Chrome()
wait = WebDriverWait(driver, 10)

driver.get('https://www.release.tdnet.info/index.html')

iframe = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "iframe[src='/onsf/TDJFSearch/I_head']")))
driver.switch_to.frame(iframe)

today = int(datetime.today().strftime('%Y%m%d'))
TargetStartDate = today
TargetEndDate = today
print(f'開始日時:{TargetStartDate} 11:30 ~ 終了日時:{TargetEndDate} 15:20')

Select(driver.find_element(By.NAME, 't0')).select_by_value(str(TargetStartDate))
Select(driver.find_element(By.NAME, 't1')).select_by_value(str(TargetEndDate))

input_element = wait.until(EC.visibility_of_element_located((By.ID, 'freewordtxt')))
input_element.send_keys('自己株')

button = wait.until(EC.element_to_be_clickable((By.ID, 'searchbtn')))
button.click()
time.sleep(10)  #これを入れないとデータが表示されない時があった

iframe = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "iframe[src='/onsf/TDJFRESULT_INITIAL.html']")))
driver.switch_to.frame(iframe)

soup = BeautifulSoup(driver.page_source, 'html.parser')

DateList = []
for td_tag in soup.find_all('td', class_='time'):
    dt_object = datetime.strptime(td_tag.get_text(strip=True), '%Y/%m/%d %H:%M')
    DateList.append(dt_object.strftime('%Y%m%d%H%M'))
    
CodeList = []
for td_tag in soup.find_all('td', class_='code'):
    CodeList.append(td_tag.get_text(strip=True))
    
pdf_links = []
TitleList = []
for a_tag in soup.find_all('a', href=True):
    if a_tag['href'].endswith('.pdf'):
        pdf_links.append(a_tag['href'])
        TitleList.append(a_tag.text.strip())

org = pd.DataFrame(data={'date':DateList, 'code':CodeList, 'pdf_link':pdf_links, 'title':TitleList})
if len(org) > 0:
    org = org[(org['date'] > f'{TargetStartDate}1130') & (org['date'] <= f'{TargetEndDate}1520')].sort_values(by='date').reset_index(drop=True)

if len(org) > 0: 
    if len(org) < 200:
        print(f'{len(org)}件PDF出力します。')
        
        TitleFilePath = r"R:\B984\Users\Kikuchi\PM\Analysis\buyback\Data\PDFtitle.xlsx"
        #PDFファイル名とタイトルの対応CSVファイルを読み込み
        title = pd.read_excel(TitleFilePath)
        AddFileList = []
        AddTitleList = []
        
        for i in range(len(org)):
            response = requests.get('https://www.release.tdnet.info' + org['pdf_link'][i], stream=True)
            save_path = SaveDir + org['date'][i] + '_' + org['code'][i] + '.pdf'
            PrvFileNum = len(glob.glob(SaveDir + org['date'][i] + '_' + org['code'][i] + '*.pdf'))
            if PrvFileNum > 0:
                save_path = SaveDir + org['date'][i] + '_' + org['code'][i] + f'_{PrvFileNum+1}.pdf'

            with open(save_path, 'wb') as pdf_file:
                for chunk in response.iter_content(chunk_size=1024):
                    pdf_file.write(chunk)
                    
            
            if PrvFileNum > 0:
                AddFileList.append(org['date'][i] + '_' + org['code'][i] + f'_{PrvFileNum+1}')
                AddTitleList.append(org['title'][i])
            else:
                AddFileList.append(org['date'][i] + '_' + org['code'][i])
                AddTitleList.append(org['title'][i])
                
                
        #PDFファイル名とタイトルの対応CSVファイルに追加
        add = pd.DataFrame(data={'FileName':AddFileList, 'title':AddTitleList})
        title = pd.concat([title, add]).sort_values(by='FileName').reset_index(drop=True)
        title.to_excel(TitleFilePath, index=False)

        print('出力完了')
        
    else:
        print(f'{TargetStartDate}~{TargetEndDate}  200件以上ヒットしているようなので、PDF出力しません。')
else:
    print('該当件数なし。PDF出力しません。')
