{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIXの現在時点のウェイトと予想のウェイトを求める\n",
    "- FFW_OLDは今日時点のFFW、FFW_NEWは現時点で予測できる全てを織り込んだもの。実際には2期先を見に行くことになる。\n",
    "- 定期予想TOPIX_FFW_ESTIMATEに予測値が入っているものはそれを入っていない場合は基礎情報から\n",
    "- 移行係数は将来０になるものは０、１になるものは1とする\n",
    "- 今日以降にTOPIXに算入される銘柄は基礎情報に入っていないので変更予告情報に追加された時点で加える\n",
    "- 上場廃止銘柄は変更予告情報に追加された時点でFFW_OLDを０にする"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FFW_NEWとHAKKOUZUMI_NEWを求める必要がある"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "settings_pyodbc = {\"DRIVER\":\"{Oracle in OraClient12Home1}\", \n",
    "                    \"SERVER\":\"E03H.WORLD\", \n",
    "                    \"DBQ\":\"E03H\", \n",
    "                    \"UID\":\"DAZ91001\", \n",
    "                    \"PWD\":\"617030\"}\n",
    "#sqlの呼び出し関数\n",
    "def sql(query):\n",
    "    cnxn = pyodbc.connect(**settings_pyodbc)\n",
    "    return pd.read_sql(query, cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 50)\n",
    "pd.set_option('display.max_rows', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = datetime.date.today().strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ポジション日の上場株数とFFWと基準値段\n",
    "def sql_ffw_old():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    CODE,\n",
    "    INDST,\n",
    "    ROUND(JOJOKABUSU / FFW, 0) as HAKKOUZUMI_OLD,\n",
    "    FFW as FFW_OLD,\n",
    "    SIZE2,\n",
    "    1 as JOIN_FLG\n",
    "FROM\n",
    "    PT2.V_MD_EQ_BASE_TOPIX\n",
    "\n",
    "WHERE\n",
    "    D_DATE = '{today}' and\n",
    "    SIZE2<=7 \n",
    "'''\n",
    "    return sql(query)\n",
    "df_ffw_old = sql_ffw_old()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_ffw_new():\n",
    "    query = f'''\n",
    "SELECT\n",
    "  CODE,\n",
    "  FFW_NEW\n",
    "FROM\n",
    "  PTEUC.TOPIX_FFW_ESTIMATE\n",
    "WHERE \n",
    "  D_DATE  = '{today}' \n",
    "    '''\n",
    "    return sql(query)\n",
    "df_ffw_new = sql_ffw_new()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# イベント日の指数用上場株数を予想する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#当日以降、イベント日までの前営業日\n",
    "#(増減発行済株数*FFW)=ADD_JOJOKABUSUを発行済株数に割り戻すために、今日以降変更予告情報の最終日までの日付一覧を作成する。各日付の各銘柄のFFWを求めるため。\n",
    "def sql_calendar():\n",
    "    query = f'''\n",
    "select\n",
    "    D_DATE,\n",
    "    1 as JOIN_FLG\n",
    "from\n",
    "    PT2.VWO_FN_CALENDAR\n",
    "where\n",
    "    E_FLG = 1 and\n",
    "    D_DATE > '{today}' and\n",
    "    D_DATE<= (SELECT\n",
    "  MAX(CHG_DATE)\n",
    "FROM\n",
    "  PT2.V_MD_CHG_BASE_TOPIX \n",
    ")\n",
    "    '''\n",
    "    return sql(query)\n",
    "df_calendar = sql_calendar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#予告情報にFFWの変更がある銘柄\n",
    "#DBのJOJOKABUSUを発行済ベースに変換するため\n",
    "def sql_fr():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    CHG_DATE as D_DATE,\n",
    "    CODE,\n",
    "    FFW_NEW as FFW_YOKOKU\n",
    "FROM\n",
    "    PT2.V_MD_CHG_BASE_TOPIX \n",
    "\n",
    "WHERE\n",
    "    CHG_DATE > '{today}' and\n",
    "    EVENT_CODE = 'FR'    \n",
    "    '''\n",
    "    return sql(query)\n",
    "df_fr = sql_fr()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加える株数\n",
    "#ここのADD_JOJOKABUSUはFFWがかかっている\n",
    "def sql_add():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    A.CODE,\n",
    "    A.CHG_DATE as D_DATE,\n",
    "    A.ADD_JOJOKABUSU\n",
    "FROM\n",
    "    PT2.V_MD_CHG_BASE_TOPIX A,\n",
    "    PT2.V_MD_EQ_BASE_TOPIX_S B\n",
    "    \n",
    "WHERE\n",
    "    A.CODE = B.CODE and\n",
    "    A.CHG_DATE > '{today}' and\n",
    "    B.D_DATE = '{today}' and\n",
    "    NOT(A.EVENT_CODE IN ('FR', '00', '19')) and \n",
    "    B.SIZE2 <= 7\n",
    "    '''\n",
    "    return sql(query)\n",
    "df_add = sql_add()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JOJOKABUSUを実際の株式数に割り戻すため日付ごと銘柄ごとののFFWを求める"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#イベント日までの前営業日×CODEをする\n",
    "df_ffw_date = pd.merge(df_calendar, df_ffw_old, on='JOIN_FLG')\n",
    "#\n",
    "df_ffw_date1 = pd.merge(df_ffw_date, df_fr, on=['D_DATE', 'CODE'], how='left').sort_values(['CODE', 'D_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw_date1['FFW_YOKOKU'] = df_ffw_date1.groupby('CODE')['FFW_YOKOKU'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#変更予告情報を加味したその時のFFW\n",
    "df_ffw_date1['FFW_REAL'] = df_ffw_date1['FFW_YOKOKU'].fillna(df_ffw_date1['FFW_OLD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add1 = pd.merge(df_add, df_ffw_date1[['CODE', 'D_DATE', 'FFW_REAL']], on=['CODE', 'D_DATE'], how= 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add1['HAKKOUZUMI_ADD'] = df_add1['ADD_JOJOKABUSU']/df_add1['FFW_REAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_add_sum = df_add1.groupby('CODE')[['HAKKOUZUMI_ADD']].sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 元のテーブルに変更予告情報の発行済み株数の増減を加える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw_old1 = pd.merge(df_ffw_old, df_add_sum, on='CODE', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw_old1['HAKKOUZUMI_ADD'] =  round(df_ffw_old1['HAKKOUZUMI_ADD'].fillna(0), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw_old1['HAKKOUZUMI_NEW'] = df_ffw_old1['HAKKOUZUMI_OLD'] + df_ffw_old1['HAKKOUZUMI_ADD'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定期見直し銘柄は自分たちの予想したFFW_NEWを加える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw = pd.merge(df_ffw_old1, df_ffw_new, on=['CODE'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 新規上場銘柄を行に加える"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#現時点ではtopixには組み入れられていないが将来TOPIXに組み入れられる銘柄\n",
    "#テクニカル上場している場合は新旧２つの同じ会社が行となるが上場廃止予定の銘柄のFFW_NEWは0になるため大丈夫\n",
    "def sql_sinki():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    A.CODE,\n",
    "    A.INDST_NEW AS INDST,\n",
    "    B.SIZE2_NEW as SIZE2,\n",
    "    A.ADD_JOJOKABUSU/ A.FFW_NEW HAKKOUZUMI_OLD,\n",
    "    0 as FFW_OLD,\n",
    "    A.FFW_NEW,\n",
    "    1 as SINKI_FLG\n",
    "FROM\n",
    "    PT2.V_MD_CHG_BASE_TOPIX A,\n",
    "    PT2.V_MD_CHG_BASE_TOPIX B\n",
    "WHERE\n",
    "    A.CODE = B.CODE and\n",
    "    A.CHG_DATE = B.CHG_DATE and\n",
    "    A.EVENT_CODE = '00' and\n",
    "    B.EVENT_CODE = 'SK' and\n",
    "    B.SIZE2_NEW < = '7' and\n",
    "    A.CHG_DATE > '{today}' \n",
    "    '''\n",
    "    return sql(query)\n",
    "df_sinki = sql_sinki()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinki1 = pd.merge(df_sinki, df_add_sum, on='CODE', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinki1['HAKKOUZUMI_ADD'] = df_sinki1['HAKKOUZUMI_ADD'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sinki1['HAKKOUZUMI_NEW'] = df_sinki1['HAKKOUZUMI_OLD'] + df_sinki1['HAKKOUZUMI_ADD'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw1 = pd.concat([df_ffw, df_sinki1])\n",
    "df_ffw1['SINKI_FLG'] = df_ffw1['SINKI_FLG'].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 上場廃止銘柄のFFW_NEWを0にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_haisi():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    CODE,\n",
    "    '1' as HAISI_FLG\n",
    "FROM\n",
    "    PT2.V_MD_CHG_BASE_TOPIX\n",
    "WHERE\n",
    "    CHG_DATE > '{today}' and\n",
    "    EVENT_CODE = '19' and\n",
    "    SHIJO_OLD= 1\n",
    "    '''\n",
    "    return sql(query)\n",
    "df_haisi = sql_haisi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw2 = pd.merge(df_ffw1, df_haisi, on='CODE', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw2['HAISI_FLG'] = df_ffw2['HAISI_FLG'].fillna('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#上場廃止予定銘柄のFFW_NEWを0にする。実際は廃止が確定してから上場廃止になるのは数日なので意味ないかも。\n",
    "#管理銘柄の時点で０にするのもいいかもしれない\n",
    "df_ffw2.loc[(df_ffw2['HAISI_FLG']=='1'), 'FFW_NEW'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 流動性係数、移行係数を付ける"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 現在の流動性係数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_tyousei_keisu():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    CODE, \n",
    "    TYOUSEI_KEISU_OLD,\n",
    "    TYOUSEI_KEISU_NEW\n",
    "FROM\n",
    "    PTEUC.TOPIX_FFW_TYOUSEI_KEISU_ESTIMATE\n",
    "WHERE\n",
    "    D_DATE = '{today}' \n",
    "    '''\n",
    "    return sql(query)\n",
    "df_tyousei_keisu = sql_tyousei_keisu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#移行係数は除外される銘柄は0，回復していくものは1にする\n",
    "def sql_ikou_keisu_old():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    CODE,\n",
    "    IKOU_KEISU as IKOU_KEISU_OLD\n",
    "FROM\n",
    "    PTEUC.TOPIX_FFW_IKOU_KEISU\n",
    "WHERE\n",
    "    FFW_DATE = (\n",
    "        SELECT\n",
    "            MAX(FFW_DATE)\n",
    "        FROM\n",
    "            PTEUC.TOPIX_FFW_IKOU_KEISU\n",
    "        WHERE\n",
    "            FFW_DATE < '{today}'\n",
    "    ) \n",
    "    '''\n",
    "    return sql(query)\n",
    "df_ikou_keisu_old = sql_ikou_keisu_old()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#移行係数は除外される銘柄は0，回復していくものは1にする\n",
    "def sql_ikou_keisu_new():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    CODE,\n",
    "    IKOU_KEISU as IKOU_KEISU_NEW\n",
    "FROM\n",
    "    PTEUC.TOPIX_FFW_IKOU_KEISU\n",
    "WHERE\n",
    "    FFW_DATE = (\n",
    "        SELECT\n",
    "            MAX(FFW_DATE)\n",
    "        FROM\n",
    "            PTEUC.TOPIX_FFW_IKOU_KEISU\n",
    "    ) \n",
    "    '''\n",
    "    return sql(query)\n",
    "df_ikou_keisu_new = sql_ikou_keisu_new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw_keisu = pd.merge(df_ffw2, df_tyousei_keisu, on=['CODE'], how='left')\n",
    "df_ffw_keisu1 = pd.merge(df_ffw_keisu, df_ikou_keisu_old, on=['CODE'], how='left')\n",
    "df_ffw_keisu2 = pd.merge(df_ffw_keisu1, df_ikou_keisu_new, on=['CODE'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw_keisu2['TYOUSEI_KEISU_OLD'] = df_ffw_keisu2['TYOUSEI_KEISU_OLD'].fillna(1)\n",
    "df_ffw_keisu2['TYOUSEI_KEISU_NEW'] = df_ffw_keisu2['TYOUSEI_KEISU_NEW'].fillna(1)\n",
    "df_ffw_keisu2['IKOU_KEISU_OLD'] = df_ffw_keisu2['IKOU_KEISU_OLD'].fillna(1)\n",
    "df_ffw_keisu2['IKOU_KEISU_NEW'] = df_ffw_keisu2['IKOU_KEISU_NEW'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFW_NEWを埋める\n",
    "# すでに値が入っている銘柄は定期見直し銘柄or新規上場銘柄。NaNの銘柄には現在のFFW_OLDを調整係数と移行係数適用前に戻してから再度FDFW_NEWを計算する\n",
    "def func_ffw_new(x):\n",
    "    #定期見直しでも新規上場でもない場合\n",
    "    if x['IKOU_KEISU_NEW'] == 0:\n",
    "        return 0\n",
    "    elif pd.isnull(x['FFW_NEW']):\n",
    "        ffw_raw = x['FFW_OLD'] / (x['TYOUSEI_KEISU_OLD'] * x['IKOU_KEISU_OLD'])\n",
    "        return round(ffw_raw * x['TYOUSEI_KEISU_NEW'] * x['IKOU_KEISU_NEW'], 5)\n",
    "    else:\n",
    "        return x['FFW_NEW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw_keisu2['FFW_NEW'] = df_ffw_keisu2.apply(lambda x: func_ffw_new(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基準値からウェイトを計算する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_std():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    CODE,\n",
    "    NAME,\n",
    "    SUBSTR(ACCT1_MD, 0, 2) as PERIODM,\n",
    "    SEIRI_KANRI_FLG,\n",
    "    STD_PR as STD_PR_OLD\n",
    "FROM\n",
    "    PT2.V_RL_JSM_EQ\n",
    "WHERE\n",
    "    SHIJO = '1'\n",
    "    '''\n",
    "    return sql(query)\n",
    "df_std = sql_std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_bunkatu():\n",
    "    query = f'''\n",
    "SELECT\n",
    "    CODE,\n",
    "    ROUND(EXP(SUM(LN(ALOC_RT_R / ALOC_RT_L))), 2) as BUNKATU\n",
    "FROM\n",
    "    PT2.V_MD_CHG_BASE_TOPIX\n",
    "WHERE\n",
    "    EVENT_CODE IN( '15', 'B1') and\n",
    "    CHG_DATE > '{today}' \n",
    "GROUP BY\n",
    "    CODE\n",
    "    '''\n",
    "    return sql(query)\n",
    "df_bunkatu = sql_bunkatu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std1 = pd.merge(df_std, df_bunkatu, on=['CODE'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std1['BUNKATU'] = df_std1['BUNKATU'].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_std1['STD_PR_NEW'] = df_std1['STD_PR_OLD'] / df_std1['BUNKATU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 元のテーブルに基準値を追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw_std = pd.merge(df_ffw_keisu2, df_std1, on=['CODE'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#売買代金のメジアン\n",
    "def sql_median(days):\n",
    "    query = f'''\n",
    "SELECT\n",
    "    CODE,\n",
    "    MEDIAN(NVL(ADJ_AMT0,0)) as AMT_MEDIAN{days}\n",
    "FROM\n",
    "    PT2.V_TS_EQ_DLY\n",
    "WHERE\n",
    "    SHIJO = '1' and\n",
    "    D_DATE >= (\n",
    "        SELECT\n",
    "            LAG_DATE\n",
    "        FROM\n",
    "            (\n",
    "                select\n",
    "                    D_DATE,\n",
    "                    LAG(D_DATE, {days}) OVER(ORDER BY D_DATE) as LAG_DATE\n",
    "                from\n",
    "                    PT2.VWO_FN_CALENDAR\n",
    "                where\n",
    "                    E_FLG = 1\n",
    "            )\n",
    "        WHERE\n",
    "            D_DATE = '{today}'\n",
    "    ) and\n",
    "    D_DATE < '{today}'\n",
    "GROUP BY CODE\n",
    "    '''\n",
    "    return sql(query)\n",
    "df_median = pd.merge(sql_median(20), sql_median(60), on=['CODE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw_std1 = pd.merge(df_ffw_std, df_median, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw_std1['D_DATE'] = str(today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ffw_std2 = df_ffw_std1.drop('JOIN_FLG', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB挿入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_table = 'PTEUC.TOPIX_FFW_WEIGHT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_exist_today(insert_table):\n",
    "    query = f'''\n",
    "SELECT COUNT(*)    \n",
    "FROM {insert_table}\n",
    "WHERE D_DATE = '{today}'\n",
    "    '''\n",
    "    return sql(query).iloc[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Insert_DB(insert_table, df):\n",
    "        keys = ','.join(list(df.columns))\n",
    "        with pyodbc.connect(DRIVER=\"{Oracle in OraClient12Home1}\", \n",
    "                              SERVER=\"E03H.WORLD\", \n",
    "                              DBQ=\"E03H\", \n",
    "                              UID=\"DAZ91001\", \n",
    "                              PWD=\"617030\") as cnxn:\n",
    "            with cnxn.cursor() as cursor:\n",
    "                #当日が既に登録されていたら削除\n",
    "                if is_exist_today(insert_table):\n",
    "                    delete_sql = f'''\n",
    "                    DELETE\n",
    "                    FROM {insert_table}\n",
    "                    WHERE D_DATE = {today}\n",
    "                    '''\n",
    "                    cursor.execute(delete_sql)\n",
    "                #ここからDB登録\n",
    "                for row in df.values:\n",
    "                    values = ''\n",
    "                    for cell in row:\n",
    "                        if type(cell) is str:\n",
    "                            values += f\"'{cell}',\"\n",
    "                        elif pd.isna(cell) or (cell is None):\n",
    "                            values += 'NULL,'\n",
    "                        else:\n",
    "                            values += f\"{cell},\"\n",
    "                    #最後のカンマを消す\n",
    "                    values = values[0:-1]\n",
    "                    \n",
    "                    insert_sql = f'insert into {insert_table} ({keys}) VALUES ({values})'\n",
    "                    # sql実行\n",
    "                    cursor.execute(insert_sql)\n",
    "                    cursor.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "Insert_DB(insert_table, df_ffw_std2.sort_values(['CODE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
